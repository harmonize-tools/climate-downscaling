{"cells":[{"cell_type":"markdown","metadata":{},"source":["# 1. Step 1: load the necessary libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["install.packages(\"./extra_libs/ncdf4_1.22.tar.gz\",repos=NULL, type=\"source\")\n","pacman::p_load(ncdf4, startR, s2dv, CSTools, easyVerification, multiApply, ClimProjDiags, plyr, nnet, FNN, ecmwfr, devtools, lubridate)\n","\n","source(\"https://earth.bsc.es/gitlab/es/csdownscale/-/raw/master/R/Analogs.R\")\n","source(\"https://earth.bsc.es/gitlab/es/csdownscale/-/raw/master/R/Interpolation.R\")\n","source(\"https://earth.bsc.es/gitlab/es/csdownscale/-/raw/master/R/Intbc.R\")\n","source(\"https://earth.bsc.es/gitlab/es/csdownscale/-/raw/master/R/Intlr.R\")\n","source(\"https://earth.bsc.es/gitlab/es/csdownscale/-/raw/master/R/LogisticReg.R\")\n","source(\"https://earth.bsc.es/gitlab/es/csdownscale/-/raw/master/R/Utils.R\")"]},{"cell_type":"markdown","metadata":{},"source":["# Step 2: define parameters\n","Run the code box to create the necessary parameters:\n","* var_name must be the same in the filename and the variable in the netcdf (the sample data is only ready to work with t2m)\n","* A long (about 30 years) reference period is necessary to calibrate the forecast and assess its quality (the sample data covers the 20-year period from 1996 to 2015)\n","* leadtimes indicate the months ahead of the seaonal prediction starting at the forecast_issue_date "]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["#climate variable (the same code is needed as variable name of the netcdf file and in the file name)\n","var_name = 't2m' # 2m temperature\n","\n","# reference period, forecast issue date and leadtimes\n","reference_period <- c(1996:2015)\n","forecast_issue_date <- '2024-04'\n","leadtimes <- indices(1:3)\n","\n","# configuration of sdate_hcst (array containing the initialisation dates of the reference period)\n","sdate_hcst <- paste0(reference_period, substr(forecast_issue_date,6,7))\n","\n","# configuration of sdate_fcst (array containing the initialisation dates of the forecast)\n","sdate_fcst <- paste0(substr(forecast_issue_date,1,4), substr(forecast_issue_date,6,7))\n","\n","# path where to find the sample data\n","exp_path <- paste0('./sample_data/ecmwf51/$var$_$sdate$01.nc')  \n","obs_path <- paste0('./sample_data/era5land/$var$_$date$.nc')\n","obs_gridref <- paste0('./sample_data/era5land/', var_name, '_', reference_period[1], substr(forecast_issue_date,6,7), '.nc') "]},{"cell_type":"markdown","metadata":{},"source":["# Step 3: SELECTION of the region boundaries\n","\n","The sample data is prepared for reginos inside lons (-85, -25) and lats (-15, 25). See [Hotspots.md](https://github.com/harmonize-tools/climate-downscaling/blob/main/Hotspots.md) for more information.\n","\n","Run the following lines of code after modifying them if you want to select a different region:"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["region.name <- 'Cajamarca (Colombia)' # name that will appear in the plot's title\n","lons.min <- -78    \n","lons.max <- -72  \n","lats.min <- 1.5   \n","lats.max <- 7.5  "]},{"cell_type":"markdown","metadata":{},"source":[">The region is now defined for our example:<br>\n",">***lons.min***: western boundary of the region. <br>\n",">***lons.max***: eastern boundary of the region.<br>\n",">***lats.min***: southern boundary of the region.<br>\n",">***lats.max***: northern boundary of the region.<br>\n"]},{"cell_type":"markdown","metadata":{},"source":["# Step 4: Load data into the session"]},{"cell_type":"markdown","metadata":{},"source":["## Load and prepare hindcast data (seasonal prediction in the reference period)"]},{"cell_type":"code","execution_count":9,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["hcst <- startR::Start(\n","        dat = exp_path,\n","        var = var_name,\n","        sdate = sdate_hcst,\n","        ensemble = 'all',\n","        time = leadtimes,\n","        latitude = values(list(lats.min, lats.max)),\n","        latitude_reorder = Sort(decreasing = T),\n","        longitude = values(list(lons.min, lons.max)),\n","        longitude_reorder = CircularSort(-180,180),\n","        synonims = list(latitude = c('lat', 'latitude'),\n","                        longitude = c('lon', 'longitude'),\n","                        ensemble=c('member','ensemble','number')),\n","        return_vars = list(latitude = 'dat',\n","                            longitude = 'dat',\n","                            time = 'sdate'),\n","        retrieve = TRUE)\n","\n","# transform the units (from Kelvin to Celsius)\n","if (attr(hcst, \"Variables\")$common[[2]]$units == 'K'){\n","    hcst <- hcst - 273.15\n","    attr(hcst, \"Variables\")$common[[2]]$units <- 'C'\n","}\n","# extract dates and coordinates\n","dates_hcst <- attr(hcst, 'Variables')$common$time\n","lats_hcst <- attr(hcst, \"Variables\")$dat1$latitude\n","lons_hcst <- attr(hcst, \"Variables\")$dat1$longitude"]},{"cell_type":"markdown","metadata":{},"source":["## Load and prepare reanalysis data to be used as reference"]},{"cell_type":"code","execution_count":10,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["# Here, the dates of the previously loaded hindcast will be used\n","# to retrieve the reanalysis. They will be the same as the hindcast times.\n","dates_file <- format(dates_hcst, '%Y%m') # Giving dates format\n","dim(dates_file) <- c(sdate = length(sdate_hcst), time = length(leadtimes)) # Specifying the dimensions \n","\n","obs <- Start(# load observational (reanalysis) data\n","    dat = obs_path,\n","    var = var_name,\n","    date = dates_file,\n","    latitude = values(list(lats.min,lats.max)),\n","    latitude_reorder = Sort(decreasing = T),\n","    longitude = values(list(lons.min, lons.max)),\n","    longitude_reorder = CircularSort(-180,180),\n","    synonims = list(longitude = c('lon', 'longitude'),\n","                    latitude = c('lat', 'latitude')),\n","    split_multiselected_dims = TRUE,\n","    return_vars = list(time = 'date',\n","                        latitude = 'dat',\n","                        longitude = 'dat'),\n","    retrieve = TRUE)\n","\n","# transform the units (from Kelvin to Celsius)\n","if (attr(obs, \"Variables\")$common[[2]]$units == 'K'){\n","    obs <- obs - 273.15\n","    attr(obs, \"Variables\")$common[[2]]$units <- 'C'\n","}\n","# extract dates and coordinates\n","dates_obs <- attr(obs, 'Variables')$common$time\n","lats_obs <- attr(obs, \"Variables\")$dat1$latitude\n","lons_obs <- attr(obs, \"Variables\")$dat1$longitude "]},{"cell_type":"markdown","metadata":{},"source":["## Load the forecast (a seasonal prediction into the future)"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["fcst <- startR::Start(\n","    dat = exp_path,\n","    var = var_name,\n","    sdate = sdate_fcst,\n","    ensemble = 'all',\n","    time = leadtimes,\n","    latitude = values(list(lats.min, lats.max)),\n","    latitude_reorder = Sort(decreasing = T),\n","    longitude = values(list(lons.min, lons.max)),\n","    longitude_reorder = CircularSort(-180,180),\n","    synonims = list(latitude = c('lat', 'latitude'),\n","                    longitude = c('lon', 'longitude'),\n","                    ensemble=c('member','ensemble','number')),\n","    return_vars = list(latitude = 'dat',\n","                        longitude = 'dat',\n","                        time = 'sdate'),\n","    retrieve = TRUE)\n","\n","# transform the units (from Kelvin to Celsius)\n","if (attr(fcst, \"Variables\")$common[[2]]$units == 'K'){\n","    fcst <- fcst - 273.15\n","    attr(fcst, \"Variables\")$common[[2]]$units <- 'C'\n","}\n","# extract dates and coordinates\n","dates_fcst <- attr(fcst, 'Variables')$common$time\n","lats_fcst <- attr(fcst, \"Variables\")$dat1$latitude\n","lons_fcst <- attr(fcst, \"Variables\")$dat1$longitude "]},{"cell_type":"markdown","metadata":{},"source":["## Calculate ensemble mean, climatologies, anomalies and seasonal averages for visualisations"]},{"cell_type":"code","execution_count":12,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["hcst.ensemble_mean <- MeanDims(hcst, dim = 'ensemble', na.rm = TRUE)\n","fcst.ensemble_mean <- MeanDims(fcst, dim = 'ensemble', na.rm = TRUE)\n","\n","hcst.clim <- MeanDims(hcst.ensemble_mean, dim = 'sdate', na.rm = TRUE)\n","obs.clim <- MeanDims(obs, dim = 'sdate', na.rm = TRUE)\n","\n","hcst.anom <- Ano(data = hcst, clim = hcst.clim)\n","fcst.anom <- Ano(data = fcst, clim = hcst.clim)\n","obs.anom <- Ano(data = obs, clim = obs.clim)\n","\n","hcst.clim_season <- MeanDims(hcst.clim, dim = 'time', na.rm = TRUE)\n","obs.clim_season <- MeanDims(obs.clim, dim = 'time', na.rm = TRUE)\n","fcst.season_av <- MeanDims(fcst, dim = 'time', na.rm = TRUE)"]},{"cell_type":"markdown","metadata":{},"source":["# Step 5: Create some plots to visualise the loaded raw data\n","\n","## Plot the climatology of the raw past predictions in comparison to the observations"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["PlotLayout(fun = PlotEquiMap, \n","            #fileout = './plot1_hindcast_climatology.png', # optional line to save the plot\n","            plot_dims = c('longitude', 'latitude'),\n","            var = ArrayToList(hcst.clim, 'time', names=''),\n","            lon = lons_hcst,\n","            lat = lats_hcst,\n","            filled.continents = FALSE,\n","            colNA = 'black',\n","            ncol = length(leadtimes),\n","            col_titles = paste0('forecast month: ', c(month(as.integer(substr(forecast_issue_date,6,7))+leadtimes-1, label = TRUE, abbr = FALSE))),\n","            nrow = 1,\n","            units = paste0(attr(hcst, \"Variables\")$common[[2]]$long_name, ' (', attr(hcst, \"Variables\")$common[[2]]$units, ')'),\n","            toptitle = paste0(region.name, ' hindcast climatology (', reference_period[1], '-',  reference_period[length(reference_period)], ')'),\n","            title_scale = 0.7,\n","            width = 10,\n","            height = 5\n"," )"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["PlotLayout(fun = PlotEquiMap, \n","            #fileout = './plot2_reanalysis_climatology.png', # optional line to save the plot\n","            plot_dims = c('longitude', 'latitude'),\n","            var = ArrayToList(obs.clim, 'time', names=''),\n","            lon = lons_obs,\n","            lat = lats_obs,\n","            filled.continents = FALSE,\n","            colNA = 'black',\n","            ncol = length(leadtimes),\n","            col_titles = paste0('forecast month: ', c(month(as.integer(substr(forecast_issue_date,6,7))+leadtimes-1, label = TRUE, abbr = FALSE))),\n","            nrow = 1,\n","            units = paste0(attr(obs, \"Variables\")$common[[2]]$long_name, ' (', attr(obs, \"Variables\")$common[[2]]$units, ')'),\n","            toptitle = paste0(region.name, ' reanalysis climatology (', reference_period[1], '-',  reference_period[length(reference_period)], ')'),\n","            title_scale = 0.7,\n","            width = 10,\n","            height = 5\n","  )"]},{"cell_type":"markdown","metadata":{},"source":["# Setp 6: SELECTION of the downscaling method\n","\n","Several methods of downscaling are available from [CSDownscale](https://earth.bsc.es/gitlab/es/csdownscale). Select **1 of the 3** options of code blocks below and modify the indicated parameters to select the interpolation method and/or the bias adjustment or linear regression method."]},{"cell_type":"markdown","metadata":{},"source":["## Option 1: interpolation\n","\n","Interpolation : Included in ```Interpolation()```. Regrid of a coarse-scale grid into a fine-scale grid, or interpolate model data into a point location. Different interpolation methods, based on different mathematical approaches, can be applied: conservative, nearest neighbour, bilinear or bicubic. It does not rely on any data for training."]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["# SELECTION: method_remap\n","\n","selection_method_remap <- 'con' # Accepted methods are \"con\", \"bil\", \"bic\", \"nn\", \"con2\", \"dis\"\n","\n","# perform dowsncaling with selected parameters\n","downscaled_fcst <- Interpolation(exp = fcst, lats = lats_hcst, lons = lons_hcst,\n","                                method_remap = selection_method_remap, \n","                                target_grid = obs_gridref, \n","                                lat_dim = \"latitude\", lon_dim = \"longitude\", region = NULL, \n","                                ncores = 7)\n","\n","# save metadata\n","downscaled_fcst$metadata <- paste0('option 1 (interpolation) with method_remap ', selection_method_remap)"]},{"cell_type":"markdown","metadata":{},"source":["## Option 2: interpolation and bias adjustment\n","\n","Interpolation plus bias adjustment : Included in Intbc(). interpolate model data into a fine-scale grid or point location. Later, a bias adjustment of the interpolated values is performed. Bias adjustment techniques include simple bias correction, calibration or quantile mapping."]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["# SELECTION: int_method and bc_method\n","\n","selection_int_method <- 'dis' # Accepted methods are \"con\", \"bil\", \"bic\", \"nn\", \"con2\", \"dis\"\n","selection_bc_method <- 'evmos' # Accepted methods are 'bias', 'evmos','mse_min', 'crps_min', 'rpc-based' and 'quantile_mapping' (but last one only recommended for precipitation)\n","                                 \n","# perform downscaling with selected parameters\n","downscaled_fcst <- Intbc(exp = hcst, obs = obs, exp_cor = fcst, \n","                                 exp_lats = lats_hcst, exp_lons = lons_hcst,\n","                                 obs_lats = lats_obs, obs_lons = lons_obs,            \n","                                 target_grid = obs_gridref,\n","                                 int_method = selection_int_method,\n","                                 bc_method = selection_bc_method,\n","                                 lat_dim = 'latitude', lon_dim = 'longitude', \n","                                 member_dim = 'ensemble',\n","                                 sdate_dim = 'sdate', \n","                                 ncores = 7)\n","\n","# save metadata\n","downscaled_fcst$metadata <- paste0('option 2 (interpolation and bias correction) with int_method ', selection_int_method, ' and bc_method ', selection_bc_method)"]},{"cell_type":"markdown","metadata":{},"source":["## Option 3: interpolation and linear regression\n","\n","Interpolation plus linear regression : Included in Intlr(..., method = 'basic'). Firstly, model data is interpolated into a fine-scale grid or point location. Later, a linear-regression with the interpolated values is fitted using high-res observations as predictands, and then applied with model data to correct the interpolated values. Stencil : Included in Intlr(..., method = '9nn'). A linear-regression with the nine nearest neighbours is fitted using high-res observations as predictands. Instead of constructing a regression model using all the nine predictors, principal component analysis is applied to the data of neighbouring grids to reduce the dimension of the predictors. The linear regression model is then built using the principal components that explain 95% of the variance. The '9nn' method does not require a pre-interpolation process.    "]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["# SELECTION: int_method\n","\n","selection_int_method <- 'con' # Accepted methods are \"con\", \"bil\", \"bic\", \"nn\", \"con2\".\n","\n","# perform downscaling with selected parameters:\n","downscaled_fcst <- Intlr(exp = hcst, obs = obs, exp_cor = fcst, \n","                                 exp_lats = lats_hcst, exp_lons = lons_hcst, \n","                                 obs_lats = lats_obs, obs_lons = lons_obs, \n","                                 int_method = selection_int_method,\n","                                 lr_method = 'basic', # Accepted methods are 'basic', 'large-scale' and '9nn'; recommended for the tutorial: 'basic' \n","                                 predictors = NULL, # Only needed if the linear regression method is set to 'large-scale'.\n","                                 target_grid = obs_gridref, #'./sample_data/era5land/t2m_199604.nc',\n","                                 lat_dim = 'latitude', lon_dim = 'longitude', \n","                                 member_dim = 'ensemble',\n","                                 sdate_dim = 'sdate', time_dim = 'time', \n","                                 loocv = TRUE, ncores = 7)\n","\n","# save metadata\n","downscaled_fcst$metadata <- paste0('option 3 (interpolation and linear regression) with int_method ', selection_int_method, ' and basic linear regression')"]},{"cell_type":"markdown","metadata":{},"source":["# Step 7: visualize raw forecast vs calibrated downscaled forecast"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["# plot raw forecast ensemble mean\n"," raw_fcst_ensemble_mean <- MeanDims(fcst, dim = 'ensemble', na.rm = TRUE)\n","\n"," # Plot raw forecast:\n"," PlotLayout(fun = PlotEquiMap, \n","             #fileout = './plot3_forecast_raw.png', # optional line to save the plot\n","             plot_dims = c('longitude', 'latitude'),\n","             var = ArrayToList(raw_fcst_ensemble_mean, 'time', names=''),\n","             lon = lons_fcst,\n","             lat = lats_fcst,\n","             filled.continents = FALSE,\n","             colNA = 'black',\n","             ncol = length(leadtimes),\n","             col_titles = paste0(c(month(as.integer(substr(forecast_issue_date,6,7))+leadtimes-1, label = TRUE, abbr = FALSE)), substr(forecast_issue_date, 1, 4)),\n","             nrow = 1,\n","             units = paste0(attr(fcst, \"Variables\")$common[[2]]$long_name, ' (', attr(fcst, \"Variables\")$common[[2]]$units, ')'),\n","             toptitle = paste0(region.name, ' raw forecast ', forecast_issue_date),\n","             title_scale = 0.7,\n","             width = 10,\n","             height = 5\n","  )"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["# create new object with downscaled forecast data\n","highres_fcst <- downscaled_fcst$data\n","# calculate ensemble mean for the visualisation:\n","highres_fcst_ensemble_mean <- MeanDims(highres_fcst, dim = 'ensemble', na.rm = TRUE)\n","\n","PlotLayout(fun = PlotEquiMap,\n","            #fileout = './plot4_forecast_downscaled.png', # optional line to save the plot\n","            plot_dims = c('longitude', 'latitude'),\n","            var = ArrayToList(highres_fcst_ensemble_mean, 'time', names=''),\n","            lon = downscaled_fcst$lon,\n","            lat = downscaled_fcst$lat,\n","            filled.continents = FALSE,\n","            colNA = 'black',\n","            ncol = length(leadtimes),\n","            col_titles = paste0(c(month(as.integer(substr(forecast_issue_date,6,7))+leadtimes-1, label = TRUE, abbr = FALSE)), substr(forecast_issue_date, 1, 4)),\n","            nrow = 1,\n","            units = paste0(attr(fcst, \"Variables\")$common[[2]]$long_name, ' (', attr(fcst, \"Variables\")$common[[2]]$units, ')'),\n","            toptitle = paste0(region.name, ' post-processed forecast ', forecast_issue_date),\n","            title_scale = 0.7,\n","            width = 10,\n","            height = 5\n"," )"]},{"cell_type":"markdown","metadata":{},"source":["# Step 8: quality assessment\n","\n","Run again the selected option for the downscaling of the forecast but this time to downscale the hindcast (and be able to assess the quality of the final product by comparing with past reference). Use the exact same option as before with the difference of selecting ```hcst``` instead of ```fcst``` and setting the parameter ```exp_cor = NULL```."]},{"cell_type":"markdown","metadata":{},"source":["## Option 1: interpolation"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["if (substr(downscaled_fcst$metadata, 8, 8) != 1){print('WARNING: this is NOT the method that was previously used to calibrate the forecast')}\n","downscaled_field <- Interpolation(exp = hcst, lats = lats_hcst, lons = lons_hcst,\n","                                 method_remap = selection_method_remap, # Accepted methods are \"con\", \"bil\", \"bic\", \"nn\", \"con2\", \"dis\"\n","                                 target_grid = obs_gridref, \n","                                 lat_dim = \"latitude\", lon_dim = \"longitude\", region = NULL, \n","                                 ncores = 7)\n","downscaled_field$obs <- obs"]},{"cell_type":"markdown","metadata":{},"source":["## Option 2: interpolation and bias adjustment"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["if (substr(downscaled_fcst$metadata, 8, 8) != 2){print('WARNING: this is NOT the method that was previously used to calibrate the forecast')}\n","downscaled_field <- Intbc(exp = hcst, obs = obs, exp_cor = NULL, \n","                                 exp_lats = lats_hcst, exp_lons = lons_hcst,\n","                                 obs_lats = lats_obs, obs_lons = lons_obs,            \n","                                 target_grid = obs_gridref,\n","                                 int_method = selection_int_method, # Accepted methods are \"con\", \"bil\", \"bic\", \"nn\", \"con2\", \"dis\"\n","                                 bc_method = selection_bc_method, # Accepted methods are 'bias', 'evmos','mse_min', 'crps_min', 'rpc-based' and 'quantile_mapping' (but last one only recommended for precipitation)\n","                                 lat_dim = 'latitude', lon_dim = 'longitude', \n","                                 member_dim = 'ensemble',\n","                                 sdate_dim = 'sdate', \n","                                 ncores = 7)"]},{"cell_type":"markdown","metadata":{},"source":["## Option 3: interpolation and linear regression"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["if (substr(downscaled_fcst$metadata, 8, 8) != 3){print('WARNING: this is NOT the method that was previouly used to calibrate the forecast')}\n","downscaled_field <- Intlr(exp = hcst, obs = obs, exp_cor = NULL, \n","                                 exp_lats = lats_hcst, exp_lons = lons_hcst, \n","                                 obs_lats = lats_obs, obs_lons = lons_obs, \n","                                 int_method = selection_int_method, # Accepted methods are \"con\", \"bil\", \"bic\", \"nn\", \"con2\".\n","                                 lr_method = 'basic', # Accepted methods are 'basic', 'large-scale' and '9nn'; recommended for the tutorial: 'basic' \n","                                 predictors = NULL, # Only needed if the linear regression method is set to 'large-scale'.\n","                                 target_grid = obs_gridref, #'./sample_data/era5land/t2m_199604.nc',\n","                                 lat_dim = 'latitude', lon_dim = 'longitude', \n","                                 member_dim = 'ensemble',\n","                                 sdate_dim = 'sdate', time_dim = 'time', \n","                                 loocv = TRUE, ncores = 7)"]},{"cell_type":"markdown","metadata":{},"source":["## Continue by calculating different metrics to assess the quality of the predictions\n","\n","The CRPSS (Continuous Ranked Probability Skill Score) is typically used to evaluate the entire continuous probability distribution. It compares the probabilistic prediction against a reference prediction (climatological forecast). A positive CRPSS (up to 1) indicates that the prediction is better (in terms of predicting the whole distribution) than the reference hindcast, while a negative CRPSS indicates that the prediction is worse (in terms of predicting the whole distribution) than the reference hindcast.\n","\n","The BSS10 and BSS90 (Brier Skill Score of the 10th and 90th percentile respectively) are used to evaluate the tails of the probability distribution (extremes). Positive values (up to 1) of BSS10 indicate that the seasonal prediction system is able to predict the abnormally low mean temperatures (or whichever is the variable), whereas positive values (up to 1) of BSS90 depicts skill in predicting abnormally high mean temperatures. As in the above skill score, the reference forecast used is the climatological forecast. The climatological forecast assigns, by definition, a probability of 0.1 to mean temperatures occurring below the 10th percentile of the climatological distribution, and the same probability for temperatures occurring above the 90th percentile of the same distribution."]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["crpss <- veriApply('EnsCrpss', fcst = downscaled_field$data, obs = downscaled_field$obs,\n","                tdim = which(names(dim(downscaled_field$data)) == 'sdate'), \n","                ensdim = which(names(dim(downscaled_field$data)) == 'ensemble'), na.rm = TRUE)[[1]]\n","bss10 <- veriApply('EnsRpss', fcst = downscaled_field$data, obs = downscaled_field$obs,\n","                prob = 1/10, tdim = which(names(dim(downscaled_field$data)) == 'sdate'), \n","                ensdim = which(names(dim(downscaled_field$data)) == 'ensemble'), na.rm = TRUE)[[1]] \n","bss90 <- veriApply('EnsRpss', fcst = downscaled_field$data, obs = downscaled_field$obs,\n","                prob = 9/10, tdim = which(names(dim(downscaled_field$data)) == 'sdate'), \n","                ensdim = which(names(dim(downscaled_field$data)) == 'ensemble'), na.rm = TRUE)[[1]] \n","\n","PlotLayout(fun = PlotEquiMap, \n","    #fileout = './plot5_skill_assessment.png', # optional line to save the plot\n","    plot_dims = c('longitude', 'latitude'),\n","    var = append(append(ArrayToList(crpss, 'time', names=''), ArrayToList(bss10, 'time', names='')), ArrayToList(bss90, 'time', names='')),\n","    layout_by_rows = FALSE,\n","    colNA = 'black',\n","    brks = seq(0,1,0.1),\n","    col_inf = 'grey',\n","    cols = c('#f7fcf5', '#e5f5e0', '#c7e9c0', '#a1d99b', '#74c476', '#41ab5d', '#238b45', '#006d2c', '#00441b', '#00441b'),\n","    lon = lons_obs,\n","    lat = lats_obs,\n","    filled.continents = FALSE, \n","    nrow = length(leadtimes),\n","    row_titles = paste0('leadtime: ', leadtimes),\n","    ncol = 3,\n","    col_titles = c('CRPSS', 'BSS10', 'BSS90')\n",")"]}],"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"codemirror_mode":"r","file_extension":".r","mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.6.1"}},"nbformat":4,"nbformat_minor":4}
